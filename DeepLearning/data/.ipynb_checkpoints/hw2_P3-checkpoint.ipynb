{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import all images from the 6 categories and reshape them to (64,64,3). We will make one  array containing all images and another housing their labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from skimage.io import imread\n",
    "from skimage.color import gray2rgb\n",
    "from skimage.transform import resize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to having a very limited amount of computational power, I elect to resize each image to a size of (64,64,3) so that computations become tractable and displayable on this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getImages(paths, alllabels):\n",
    "    images, labels = [],[]\n",
    "    for p in range(len(paths)):\n",
    "        imagesList = listdir(paths[p])\n",
    "        for image in imagesList:\n",
    "            im = imread(paths[p] + image)\n",
    "            if len(im.shape) == 2:\n",
    "                im = gray2rgb(im)\n",
    "            im = resize(im, (64,64,3), preserve_range=False)\n",
    "            images.append(im)\n",
    "            labels.append(alllabels[p])\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/Users/Karel/cs/cse6240/hw2/'\n",
    "imlabels = ['person','animal','plant','sport','geology','fungus']\n",
    "images, labels = getImages([path+'n00007846/',path+'n00015388/',\\\n",
    "                    path+'n00017222/',path+'n00523513/',path+'n09287968/',path+'n12992868/'],\\\n",
    "                          imlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_img = Input(shape=(64, 64, 3))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7189 samples, validate on 1798 samples\n",
      "Epoch 1/3\n",
      "7189/7189 [==============================] - 770s - loss: 0.6597 - mean_squared_error: 0.0624 - val_loss: 0.6205 - val_mean_squared_error: 0.0441\n",
      "Epoch 2/3\n",
      "7189/7189 [==============================] - 524s - loss: 0.5985 - mean_squared_error: 0.0351 - val_loss: 0.5887 - val_mean_squared_error: 0.0304\n",
      "Epoch 3/3\n",
      "7189/7189 [==============================] - 507s - loss: 0.5864 - mean_squared_error: 0.0301 - val_loss: 0.5796 - val_mean_squared_error: 0.0273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14bc62750>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=3,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = Model(input_img,encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_encoded = encoder.predict(x_train)\n",
    "test_encoded = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7189, 8192)\n"
     ]
    }
   ],
   "source": [
    "train_encoded1 = train_encoded.reshape(len(train_encoded),16*16*32)\n",
    "print train_encoded1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(train_encoded1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_encoded1 = test_encoded.reshape(len(test_encoded),16*16*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pred = knn.predict(test_encoded1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeConfusion(xpred,xtrue):\n",
    "    return confusion_matrix(xtrue, xpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the autoencoder confusion matrix using euclidean distance for kNN and its corresponding accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115  26 134   6  39  14]\n",
      " [ 32  84  55   2  57   4]\n",
      " [ 46   9 266   4  17  11]\n",
      " [ 67  18 103  36  26   7]\n",
      " [ 41  33  58   1 103   2]\n",
      " [ 94  18 176   9  33  52]]\n",
      "\n",
      "Accuracy: 0.364850\n"
     ]
    }
   ],
   "source": [
    "confusionMatrix = makeConfusion(x_pred,y_test)\n",
    "print confusionMatrix\n",
    "print '\\nAccuracy: %f' %accuracy_score(x_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the same analysis but using the Pearson correlation coefficient as our similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110  28 110  20  50  16]\n",
      " [ 43  82  55   5  47   2]\n",
      " [ 43  11 265   5  22   7]\n",
      " [ 57  26 101  43  19  11]\n",
      " [ 33  37  62   8  96   2]\n",
      " [ 88  20 182   9  29  54]]\n",
      "\n",
      "Accuracy: 0.361513\n"
     ]
    }
   ],
   "source": [
    "knn_P = KNeighborsClassifier(n_neighbors=5, metric='correlation',algorithm='brute')\n",
    "knn_P.fit(train_encoded1, y_train)\n",
    "x_pred_P = knn_P.predict(test_encoded1)\n",
    "confusionMatrix_P = makeConfusion(x_pred_P,y_test)\n",
    "print confusionMatrix_P\n",
    "print '\\nAccuracy: %f' %accuracy_score(x_pred_P,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getRgbColumns(imageMatrix):\n",
    "    r, g, b = [],[],[]\n",
    "    for row in imageMatrix:\n",
    "        for col in row:\n",
    "            r.append(col[0])\n",
    "            g.append(col[1])\n",
    "            b.append(col[2])\n",
    "    return r,g,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getBins(arr):\n",
    "    return np.histogram(arr, bins=np.arange(0,1+float(1)/256,float(1)/256))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFV(arr1,arr2,arr3):\n",
    "    return np.concatenate((arr1,arr2,arr3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeAllFV(samplesMatrix):\n",
    "    fvs = []\n",
    "    for sample in samplesMatrix:\n",
    "        r,g,b = getRgbColumns(sample)\n",
    "        rbin,gbin,bbin = getBins(r), getBins(g), getBins(b)\n",
    "        fvs.append(makeFV(rbin,gbin,bbin))\n",
    "    return fvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_rgb = makeAllFV(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_rgb = makeAllFV(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use kNN with euclidean distance metric to generate the confusion matrix and accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112  88  52  29  45   8]\n",
      " [ 26 151   8  14  22  13]\n",
      " [ 86  82 147  16  12  10]\n",
      " [ 62  73  30  54  16  22]\n",
      " [ 33  71  32   8  87   7]\n",
      " [ 93  90  51  28  19 101]]\n",
      "\n",
      "Accuracy: 0.362625\n"
     ]
    }
   ],
   "source": [
    "knn_RGB = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn_RGB.fit(x_train_rgb, y_train)\n",
    "x_pred_RGB = knn_RGB.predict(x_test_rgb)\n",
    "confusionMatrix_RGB = makeConfusion(x_pred_RGB,y_test)\n",
    "print confusionMatrix_RGB\n",
    "print '\\nAccuracy: %f' %accuracy_score(x_pred_RGB,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will do the same process, but using the Pearson correlation coefficient to rank closeness of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 97  59  59  38  61  20]\n",
      " [ 30 131  17  16  34   6]\n",
      " [ 73  44 183  21  23   9]\n",
      " [ 53  55  39  68  22  20]\n",
      " [ 36  50  33  13 102   4]\n",
      " [ 98  45  78  32  28 101]]\n",
      "\n",
      "Accuracy: 0.379310\n"
     ]
    }
   ],
   "source": [
    "knn_RGB_P = KNeighborsClassifier(n_neighbors=5, metric='correlation',algorithm='brute')\n",
    "knn_RGB_P.fit(x_train_rgb, y_train)\n",
    "x_pred_RGB_P = knn_RGB_P.predict(x_test_rgb)\n",
    "confusionMatrix_RGB_P = makeConfusion(x_pred_RGB_P,y_test)\n",
    "print confusionMatrix_RGB_P\n",
    "print '\\nAccuracy: %f' %accuracy_score(x_pred_RGB_P,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets convert our data from rgb to hsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "x_train_hsv, x_test_hsv = [],[]\n",
    "for image in x_train:\n",
    "    x_train_hsv.append(color.rgb2hsv(image))\n",
    "for image in x_test:\n",
    "    x_test_hsv.append(color.rgb2hsv(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reuse some of the functions used in RGB Histogram, but slightly alter others to fit the needs of the hsv representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBins2(arr, numBins):\n",
    "    return np.histogram(arr, bins=np.arange(0,1+float(1)/numBins,float(1)/numBins))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeAllFV2(samplesMatrix):\n",
    "    fvs = []\n",
    "    for sample in samplesMatrix:\n",
    "        h,s,v = getRgbColumns(sample)\n",
    "        hbin,sbin,vbin = getBins2(h,180), getBins2(s,256), getBins2(v,256)\n",
    "        fvs.append(makeFV(hbin,sbin,vbin))\n",
    "    return fvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make the feature vector representation of our hsv data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_hsv1 = makeAllFV2(x_train_hsv)\n",
    "x_test_hsv1 = makeAllFV2(x_test_hsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use kNN with euclidean distance metric to generate the confusion matrix and accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 87 100  53  16  40  10]\n",
      " [ 22 151  13   6  23   9]\n",
      " [ 61  80 192  17  15  25]\n",
      " [ 41  65  35  63  12  22]\n",
      " [ 43  70  20   6 129   6]\n",
      " [ 61 109  34  12  23 127]]\n",
      "\n",
      "Accuracy: 0.416574\n"
     ]
    }
   ],
   "source": [
    "knn_hsv = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn_hsv.fit(x_train_hsv1, y_train)\n",
    "x_pred_hsv1 = knn_hsv.predict(x_test_hsv1)\n",
    "confusionMatrix_hsv = makeConfusion(x_pred_hsv1,y_test)\n",
    "print confusionMatrix_hsv\n",
    "print '\\nAccuracy: %f' %accuracy_score(x_pred_hsv1,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will repeat this process with the Pearson correlation coefficient as the similarity metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112  58  68  20  40   8]\n",
      " [ 46 112  29   6  24   7]\n",
      " [ 71  49 229  24   9   8]\n",
      " [ 40  52  45  72   9  20]\n",
      " [ 52  54  22  11 126   9]\n",
      " [ 66  73  70  18  30 109]]\n",
      "\n",
      "Accuracy: 0.422692\n"
     ]
    }
   ],
   "source": [
    "knn_hsv_P = KNeighborsClassifier(n_neighbors=5, metric='correlation',algorithm='brute')\n",
    "knn_hsv_P.fit(x_train_hsv1, y_train)\n",
    "x_pred_hsv_P = knn_hsv_P.predict(x_test_hsv1)\n",
    "confusionMatrix_hsv_P = makeConfusion(x_pred_hsv_P,y_test)\n",
    "print confusionMatrix_hsv_P\n",
    "print '\\nAccuracy: %f' %accuracy_score(x_pred_hsv_P,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will flatten out data so each image is a one dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_svd = []\n",
    "x_test_svd = []\n",
    "for image in x_train:\n",
    "    x_train_svd.append(np.reshape(image,64*64*3))\n",
    "for image in x_test:\n",
    "    x_test_svd.append(np.reshape(image,64*64*3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform Singular Value Decomposition on the flattened vectors. Given the large number of features in each image, I elected to choose a k value of several hundred so as not to lose too much information from the original image's high dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=256)\n",
    "x_train_svd1 = svd.fit_transform(x_train_svd)\n",
    "x_test_svd1 = svd.transform(x_test_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use these vectors and analyze its accuracy using 5-NN with euclidean distance as the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114  30 110   7  23  22]\n",
      " [ 69  58  69   3  21   4]\n",
      " [ 44  10 306   4  13  13]\n",
      " [ 54  23 100  36  12  13]\n",
      " [ 68  22  83   4  85  12]\n",
      " [106   9 159   5  22  65]]\n",
      "\n",
      "Accuracy: 0.369299\n"
     ]
    }
   ],
   "source": [
    "knn_svd = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn_svd.fit(x_train_svd1, y_train)\n",
    "x_pred_svd1 = knn_svd.predict(x_test_svd1)\n",
    "confusionMatrix_svd = makeConfusion(x_pred_svd1,y_test)\n",
    "print confusionMatrix_svd\n",
    "print '\\nAccuracy: %f' %accuracy_score(x_pred_svd1,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, using 5-NN and the Pearson correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  14 116  22  15  21]\n",
      " [ 62  53  77   4  24   4]\n",
      " [ 38   6 314  12   6  14]\n",
      " [ 55  15 111  32  12  13]\n",
      " [ 71  20  94   3  81   5]\n",
      " [ 94  15 166  17  12  62]]\n",
      "\n",
      "Accuracy: 0.367075\n"
     ]
    }
   ],
   "source": [
    "knn_svd_P = KNeighborsClassifier(n_neighbors=5, metric='correlation',algorithm='brute')\n",
    "knn_svd_P.fit(x_train_svd1, y_train)\n",
    "x_pred_svd_P = knn_svd_P.predict(x_test_svd1)\n",
    "confusionMatrix_svd_P = makeConfusion(x_pred_svd_P,y_test)\n",
    "print confusionMatrix_svd_P\n",
    "print '\\nAccuracy: %f' %accuracy_score(x_pred_svd_P,y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
